{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book word frequency extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def ori_data_read(cols):\n",
    "    data = pd.read_excel('data_modified.xlsx',usecols=[cols]).values\n",
    "    output = []\n",
    "    for i in range(0,len(data)-1):\n",
    "        output.append(data[len(data)-i-1][0])\n",
    "    return output\n",
    "\n",
    "Word_col = ori_data_read(3)\n",
    "str = \"\"\n",
    "for i in range(len(Word_col)):\n",
    "    str = str + Word_col[i]\n",
    "    if(i == len(Word_col)-1):\n",
    "        break\n",
    "    str = str + \",\"\n",
    "\n",
    "params = {\n",
    "    \"content\": \"slump,crank,gorge,query,drink,faver,abbey,tangy\",\n",
    "    \"year_start\": \"1800\",\n",
    "    \"year_end\": \"2019\"\n",
    "}\n",
    "\n",
    "params[\"content\"] = str\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\",\n",
    "}\n",
    "\n",
    "html = requests.get(\"https://books.google.com/ngrams/json\", params=params, headers=headers, timeout=30).text\n",
    "time_series = pd.read_json(html, typ=\"series\")\n",
    "\n",
    "year_values = list(range(int(params['year_start']), int(params['year_end']) + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "wor = []\n",
    "value = []\n",
    "le = len(time_series[0][\"timeseries\"])\n",
    "for series in range(359):\n",
    "    dummy = []\n",
    "    wor.append(time_series[series][\"ngram\"])\n",
    "    dummy.append(time_series[series][\"ngram\"])\n",
    "    value.append(sum(time_series[series][\"timeseries\"]) / le *100000000)\n",
    "    dummy.append(sum(time_series[series][\"timeseries\"]) / le *100000000)\n",
    "    ans.append(dummy)\n",
    "\n",
    "dataframe = pd.DataFrame({'word':wor,'value':value})\n",
    "dataframe.to_csv(\"test.csv\",index=False,sep=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Momo Recite Word\" database extracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from xlsxwriter.workbook import Workbook\n",
    "workbook = Workbook('output2.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "conn=sqlite3.connect('maimemo.v3.db')\n",
    "c=conn.cursor()\n",
    "mysel=c.execute(\"select spelling,frequency,difficulty,acknowledge_rate from VOC_TB\")\n",
    "for i, row in enumerate(mysel):\n",
    "    for j, value in enumerate(row):\n",
    "        worksheet.write(i, j, value)\n",
    "workbook.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f21bb2d5c565dbc33d815445cee0d4e3f2f7951520fd8c0e3b4200672f41bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
